{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "proyectoFinalVC_redesSiamesas.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "cAzdivZQpoRV",
        "fWd3Xx9ppxvS",
        "1oh0xvI8ENcq",
        "Ca7nuxtlWB7n",
        "m6brXSvYNBZE",
        "Z3Yg1GO2v00w"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zxUqge4nUBE"
      },
      "source": [
        "# **Proyecto Final:** \n",
        "**Alumnos:** Aroca Aguilar, Antonio José y Díaz Ramírez, José Antonio  \n",
        "**Correos:** antonioaroca@correo.ugr.es y joseadr@correo.ugr.es  \n",
        "**Asignatura:** Visión por Computador  \n",
        "**Profesor:** Nicolás Pérez de la Blanca Capilla  \n",
        "**Curso:** 2020/21"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cAzdivZQpoRV"
      },
      "source": [
        "#Instalación e import necesarios"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saWPM2FeplgG"
      },
      "source": [
        "!pip install -q keras #instalamos keras en google colab"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jioKlqhrprVG"
      },
      "source": [
        "#importamos algunos modulos necesarios\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "import math \n",
        "import os\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "#importamos OpenCV para el tratamiento de imagenes\n",
        "import cv2 as cv \n",
        "from google.colab.patches import cv2_imshow #importamos el parche para poder usar imshow de opencv en colab\n",
        "\n",
        "#importamos lo necesario de keras\n",
        "import keras\n",
        "import keras.utils as np_utils\n",
        "from keras.preprocessing.image import load_img,img_to_array\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, Reshape, Lambda, Input, LeakyReLU, Dropout, MaxPooling2D, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.optimizers import SGD\n",
        "import keras.backend as K\n",
        "\n",
        "#importamos el drive\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\") #montamos el sistema de archivos"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWd3Xx9ppxvS"
      },
      "source": [
        "#Funciones implementadas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fR2pDypup2sT"
      },
      "source": [
        "\"\"\"\n",
        "funcion para cargar las imagenes de del path en un diccionario considerando como \n",
        "clave el tipo de habitacion que es, la ciudad a la que pertence y el identificador\n",
        "asociado a esa habitacion concreta.\n",
        "Entrada: la ruta de la carpeta principal donde estan contenidas las carpetas de las ims\n",
        "Salida: un diccionario con la clave ya mencionada y como valor para cada clave una\n",
        "        lista con las imagenes que pertenecen a la misma clase(clave)\n",
        "\"\"\"\n",
        "def cargarImagenes(path):\n",
        "\n",
        "  #obtenemos todos los directorios donde estan almacenadas las imagenes\n",
        "  ruta = path\n",
        "  directorios = os.listdir(ruta)\n",
        "  directorios.remove('_DS_Store')\n",
        "\n",
        "  diccionario = {}\n",
        "  for carpeta in directorios: \n",
        "\n",
        "    #recorremos cada directorio obteniendo el nombre de las imagenes que contiene\n",
        "    ruta = path + '/' + carpeta\n",
        "    imagenes = os.listdir(ruta)\n",
        "    \n",
        "    for imagen in imagenes:\n",
        "      \n",
        "      #cargamos cada imagen obtenemos su ciudad y el codigo asociado a la habitacion\n",
        "      ruta = path + '/' + carpeta + '/' + imagen\n",
        "      im = load_img(ruta,target_size=(256,256))\n",
        "      im = img_to_array(im)\n",
        "      ciudad = imagen.split('_')[0]\n",
        "      codigo = imagen.split('_')[1]\n",
        "      clave = carpeta + '_' + ciudad + '_' + codigo\n",
        "\n",
        "      #la metemos en el diccionario teniendo en cuenta si ya se han cargado mas imagenes de su misma clase previamente\n",
        "      if clave in diccionario.keys():\n",
        "        images = diccionario[clave]\n",
        "        images.append(im)\n",
        "        diccionario[clave] = images\n",
        "      else:\n",
        "        diccionario[clave] = [im]\n",
        "\n",
        "  return diccionario\n",
        "\n",
        "\"\"\"\n",
        "funcion para cargar las imagenes de la base de datos AirBnb\n",
        "Entrada: -\n",
        "Salida: un diccionario con las imagenes del trainning y otro con las del test\n",
        "\"\"\"\n",
        "def cargarImagenesAirBnb():\n",
        "\n",
        "  diccionarioTrain = cargarImagenes(\"./drive/My Drive/imagenes/Airbnb Data/Training Data\")\n",
        "  diccionarioTest = cargarImagenes(\"./drive/My Drive/imagenes/Airbnb Data/Test Data\")\n",
        "\n",
        "  return diccionarioTrain, diccionarioTest\n",
        "\n",
        "\"\"\"\n",
        "funcion para eliminar las clases que solamente tienen un ejemplo porque no van a\n",
        "tener casos positivos\n",
        "Entrada: el diccionario con todas las imagenes\n",
        "Salida: el diccionario de entradas una vez eliminadas las entradas no validas\n",
        "\"\"\"\n",
        "def eliminarEjemplosNoValidos(diccionario):\n",
        "\n",
        "  clavesEliminar = []\n",
        "\n",
        "  for clave in diccionario:\n",
        "    if len(diccionario[clave]) == 1:\n",
        "      clavesEliminar.append(clave)\n",
        "  \n",
        "  for key in clavesEliminar:\n",
        "    del diccionario[key]\n",
        "  \n",
        "  return diccionario\n",
        "\n",
        "\"\"\"\n",
        "funcion para transformar los datos de las imagenes disponibles en un diccionario\n",
        "en dos listas\n",
        "Entrada: el diccionario con todas las imagenes\n",
        "Salida: una lista con todas las imagenes del diccionario y otra lista con las clases\n",
        "        a las que pertenece cada imagen. Ambas listas siguen el mismo orden de modo \n",
        "        que clases[i] es la clase de imagenes[i]\n",
        "\"\"\"\n",
        "def leerImagenes(diccionario):\n",
        "\n",
        "  clases =[]\n",
        "  imagenes = []\n",
        "\n",
        "  for clave in diccionario:\n",
        "    for img in range(len(diccionario[clave])):\n",
        "      clases.append(clave)\n",
        "      imagenes.append(diccionario[clave][img])\n",
        "  \n",
        "  return imagenes, clases\n",
        "\n",
        "\"\"\"\n",
        "funcion para obtener los conjuntos de entrenamiento y test y sus distintas etiquetas\n",
        "en el formato correcto. (variacion de la funcion proporcionada por los profesores de \n",
        "la asignatura para la realizacion de la practica 2)\n",
        "Entrada: el diccionario con las imagenes del trainning y el diccionario con las \n",
        "        imagenes del test\n",
        "Salida: una lista con las imagenes del conjunto training barajadas, una matriz en \n",
        "        la que cada fila es una sucesion de 0s menos un 1 en la columna que represente\n",
        "        la clase a la que pertenece la imagen correspondiente, lo equivalente para \n",
        "        el conjunto test\n",
        "\"\"\"\n",
        "def cargarDatos(diccionario,diccionario_test):\n",
        "  \n",
        "  #convertimos los diccionarios en listas con la funcion leerImagenes\n",
        "  train, train_clases = leerImagenes(diccionario)\n",
        "  test, test_clases = leerImagenes(diccionario_test)\n",
        "  \n",
        "  # Pasamos los vectores de las clases a matrices. Para ello, primero pasamos las clases a números enteros\n",
        "  clases_posibles = np.unique(np.copy(train_clases))\n",
        "  train_clases = [i for i in range(len(clases_posibles)) for j in range(len(train_clases)) if train_clases[j] == clases_posibles[i]]\n",
        "  \n",
        "  clases_posibles_test = np.unique(np.copy(test_clases))\n",
        "  test_clases = [i for i in range(len(clases_posibles_test)) for j in range(len(test_clases)) if test_clases[j] == clases_posibles_test[i]]\n",
        "    \n",
        "  # Después, usamos la función to_categorical()\n",
        "  train_clases = np_utils.to_categorical(train_clases, 274)\n",
        "  test_clases = np_utils.to_categorical(test_clases, 111)\n",
        "  \n",
        "  # Barajar los datos\n",
        "  train_perm = np.random.permutation(len(train))\n",
        "  training = []\n",
        "  for i in range(len(train_perm)):\n",
        "    training.append(train[train_perm[i]])\n",
        "    \n",
        "  test_perm = np.random.permutation(len(test))\n",
        "  test_final = []\n",
        "  for i in range(len(test_perm)):\n",
        "    test_final.append(test[test_perm[i]])\n",
        "\n",
        "  #ordenamos las clases segun la permutacion de imagenes anterior\n",
        "  train_clases = train_clases[train_perm]\n",
        "  test_clases = test_clases[test_perm]\n",
        "\n",
        "  #antes de devolver lo convertimos a arrays de numpy\n",
        "  training = np.array(training)\n",
        "  test_final = np.array(test_final)\n",
        "\n",
        "  return training, train_clases, test_final, test_clases\n",
        "\n",
        "\"\"\"\n",
        "funcion para obtener el subconjunto de validacion como un subconjunto del train\n",
        "Entrada: el conjunto train y sus etiquetas y la probabilidad de que cada elemento\n",
        "        pertenezca al conjunto train\n",
        "Salida: los conjuntos de train y validacion con sus respectivas etiquetas\n",
        "\"\"\"\n",
        "def formarValidation(xTrain,yTrain,probTrain):\n",
        "\n",
        "  #creamos las variables que necesitamos\n",
        "  indicesTrain = []\n",
        "  indicesValidation = []\n",
        "  x_train = []\n",
        "  y_train =[]\n",
        "  x_val = [] \n",
        "  y_val = []\n",
        "\n",
        "  #recorremos todos los elementos de train seleccionando cuales perteneceran a train y cuales a validation\n",
        "  for i in range(len(xTrain)):\n",
        "    if np.random.rand() < probTrain:\n",
        "      indicesTrain.append(i)\n",
        "    else:\n",
        "      indicesValidation.append(i)\n",
        "\n",
        "  #creamos el nuevo conjunto train y sus etiquetas\n",
        "  for i in range(len(indicesTrain)):\n",
        "    x_train.append(xTrain[indicesTrain[i]])\n",
        "    y_train.append(yTrain[indicesTrain[i]])\n",
        "\n",
        "  #creamos el nuevo conjunto validation y sus etiquetas\n",
        "  for i in range(len(indicesValidation)):\n",
        "    x_val.append(xTrain[indicesValidation[i]])\n",
        "    y_val.append(yTrain[indicesValidation[i]])\n",
        "\n",
        "  return x_train, y_train, x_val, y_val\n",
        "\n",
        "\"\"\"\n",
        "funcion para mostrar la evolucion del accuracy y el loss del conjunto train y del \n",
        "validacion a lo largo de las epocas (funcion proporcionada por los profesores de \n",
        "la asignatura para la realizacion de la practica 2)\n",
        "Entrada: el histograma dado por el aprendizaje\n",
        "Salida: -\n",
        "\"\"\"\n",
        "def mostrarEvolucion(hist):\n",
        "\n",
        "  loss = hist.history['loss']\n",
        "  val_loss = hist.history['val_loss']\n",
        "  plt.plot(loss)\n",
        "  plt.plot(val_loss)\n",
        "  plt.legend(['Training loss', 'Validation loss'])\n",
        "  plt.show()\n",
        "\n",
        "  acc = hist.history['acc']\n",
        "  val_acc = hist.history['val_acc']\n",
        "  plt.plot(acc)\n",
        "  plt.plot(val_acc)\n",
        "  plt.legend(['Training accuracy', 'Validation accuracy'])\n",
        "  plt.show()\n",
        "\n",
        "\"\"\"\n",
        "funcion para hacer parejas de imagenes (primera version con la misma cantidad de \n",
        "parejas positivas que negativas)\n",
        "Entrada: las imagenes en forma de lista y sus etiquetas de forma categorica, tal y\n",
        "        como nos las proporciona la funcion cargarDatos\n",
        "Salida: una lista de parejas de imagenes y una lista de etiquetas podiendo ser estas\n",
        "        un 1 en caso de que ambas imagenes de la pareja pertenezca a la misma clase \n",
        "        y un 0 en caso contrario\n",
        "\"\"\"\n",
        "def make_pairs_v1(images, labels):\n",
        "\n",
        "  parejas = []\n",
        "  clasesParejas = []\n",
        "  \n",
        "  #obtenemos una lista con los indices de las imagenes que tienen cada clase\n",
        "  numClases = len(labels[0])\n",
        "  indice = []\n",
        "  for i in range(0,len(labels)):\n",
        "    for j in range(0,len(labels[i])):\n",
        "      if (labels[i][j]==1):\n",
        "        indice.append(j)\n",
        "  indice = np.array(indice)\n",
        "  idx = [np.where(indice == i)[0] for i in range(0, numClases)]\n",
        "\n",
        "  #recorremos todas las imagenes formando con cada una de ellas una pareja positiva y una negativa\n",
        "  for im in range(len(images)):\n",
        "\n",
        "    #guardamos la imagen actual y su etiqueta\n",
        "    imagenActual = images[im]\n",
        "    label = indice[im]\n",
        "    \n",
        "    #escogemos aleatoriamente otra imagen de su misma clase para formar pareja positiva\n",
        "    num_indices = np.where(indice == label)[0]\n",
        "    salir = True\n",
        "    while salir :\n",
        "      idxB = np.random.choice(idx[label])\n",
        "      if not idxB == im:\n",
        "        salir=False\n",
        "    posImage = images[idxB]\n",
        "    #añadimos la pareja y su clase\n",
        "    parejas.append([imagenActual, posImage])\n",
        "    clasesParejas.append([1])\n",
        "\t  \n",
        "    #escogemos aleatoriamente una imagen de su otra clase distinta para formar pareja negativa\n",
        "    negIdx = np.where(indice != label)[0]\n",
        "    idxC = np.random.choice(negIdx)\n",
        "    negImage = images[idxC]\n",
        "\t\t#añadimos la pareja y su clase\n",
        "    parejas.append([imagenActual, negImage])\n",
        "    clasesParejas.append([0])\n",
        "\t\n",
        "  return parejas, clasesParejas\n",
        "\n",
        "\"\"\"\n",
        "funcion para hacer parejas de imagenes (segunda version con el doble de parejas \n",
        "negativas que positivas)\n",
        "Entrada: las imagenes en forma de lista y sus etiquetas de forma categorica, tal y\n",
        "        como nos las proporciona la funcion cargarDatos\n",
        "Salida: una lista de parejas de imagenes y una lista de etiquetas podiendo ser estas\n",
        "        un 1 en caso de que ambas imagenes de la pareja pertenezca a la misma clase \n",
        "        y un 0 en caso contrario\n",
        "\"\"\"\n",
        "def make_pairs_v2(images, labels):\n",
        "\n",
        "  parejas = []\n",
        "  clasesParejas = []\n",
        "  \n",
        "  #obtenemos una lista con los indices de las imagenes que tienen cada clase\n",
        "  numClases = len(labels[0])\n",
        "  indice = []\n",
        "  for i in range(0,len(labels)):\n",
        "    for j in range(0,len(labels[i])):\n",
        "      if (labels[i][j]==1):\n",
        "        indice.append(j)\n",
        "  indice = np.array(indice)\n",
        "  idx = [np.where(indice == i)[0] for i in range(0, numClases)]\n",
        "\n",
        "  #recorremos todas las imagenes formando con cada una de ellas una pareja positiva y una negativa\n",
        "  for im in range(len(images)):\n",
        "\n",
        "    #guardamos la imagen actual y su etiqueta\n",
        "    imagenActual = images[im]\n",
        "    label = indice[im]\n",
        "    \n",
        "    #escogemos aleatoriamente otra imagen de su misma clase para formar pareja positiva\n",
        "    num_indices = np.where(indice == label)[0]\n",
        "    salir = True\n",
        "    while salir :\n",
        "      idxB = np.random.choice(idx[label])\n",
        "      if not idxB == im:\n",
        "        salir=False\n",
        "    posImage = images[idxB]\n",
        "    #añadimos la pareja y su clase\n",
        "    parejas.append([imagenActual, posImage])\n",
        "    clasesParejas.append([1])\n",
        "\t  \n",
        "    #escogemos aleatoriamente una imagen de su otra clase distinta para formar pareja negativa\n",
        "    negIdx = np.where(indice != label)[0]\n",
        "    idxC = np.random.choice(negIdx)\n",
        "    negImage = images[idxC]\n",
        "\t\t#añadimos la pareja y su clase\n",
        "    parejas.append([imagenActual, negImage])\n",
        "    clasesParejas.append([0])\n",
        "\n",
        "    #escogemos aleatoriamente otra imagen de su otra clase distinta para formar pareja negativa\n",
        "    negIdx = np.where(indice != label)[0]\n",
        "    salir = True\n",
        "    while salir:\n",
        "      idxD = np.random.choice(negIdx)\n",
        "      if not idxC == idxD:\n",
        "        salir = False\n",
        "    negImage = images[idxD]\n",
        "\t\t#añadimos la pareja y su clase\n",
        "    parejas.append([imagenActual, negImage])\n",
        "    clasesParejas.append([0])\n",
        "\t\n",
        "  return parejas, clasesParejas\n",
        "\n",
        "\"\"\"\n",
        "funcion para hacer parejas de imagenes (tercera version con el mismo numero de parejas\n",
        "negativas que positivas, pero con el doble que en la version 1)\n",
        "Entrada: las imagenes en forma de lista y sus etiquetas de forma categorica, tal y\n",
        "        como nos las proporciona la funcion cargarDatos\n",
        "Salida: una lista de parejas de imagenes y una lista de etiquetas podiendo ser estas\n",
        "        un 1 en caso de que ambas imagenes de la pareja pertenezca a la misma clase \n",
        "        y un 0 en caso contrario\n",
        "\"\"\"\n",
        "def make_pairs_v3(images, labels):\n",
        "\n",
        "  parejas = []\n",
        "  clasesParejas = []\n",
        "  \n",
        "  #obtenemos una lista con los indices de las imagenes que tienen cada clase\n",
        "  numClases = len(labels[0])\n",
        "  indice = []\n",
        "  for i in range(0,len(labels)):\n",
        "    for j in range(0,len(labels[i])):\n",
        "      if (labels[i][j]==1):\n",
        "        indice.append(j)\n",
        "  indice = np.array(indice)\n",
        "  idx = [np.where(indice == i)[0] for i in range(0, numClases)]\n",
        "\n",
        "  #recorremos todas las imagenes formando con cada una de ellas una pareja positiva y una negativa\n",
        "  for im in range(len(images)):\n",
        "\n",
        "    #guardamos la imagen actual y su etiqueta\n",
        "    imagenActual = images[im]\n",
        "    label = indice[im]\n",
        "    \n",
        "    #escogemos aleatoriamente otra imagen de su misma clase para formar pareja positiva\n",
        "    num_indices = np.where(indice == label)[0]\n",
        "    salir = True\n",
        "    while salir :\n",
        "      idxB = np.random.choice(idx[label])\n",
        "      if not idxB == im:\n",
        "        salir=False\n",
        "    posImage = images[idxB]\n",
        "    #añadimos la pareja y su clase\n",
        "    parejas.append([imagenActual, posImage])\n",
        "    clasesParejas.append([1])\n",
        "\n",
        "    #escogemos aleatoriamente otra imagen de su misma clase para formar pareja positiva\n",
        "    salir = True\n",
        "    while salir :\n",
        "      idxB = np.random.choice(idx[label])\n",
        "      if not idxB == im:\n",
        "        salir=False\n",
        "    posImage = images[idxB]\n",
        "\t\t#añadimos la pareja y su clase\n",
        "    parejas.append([imagenActual, posImage])\n",
        "    clasesParejas.append([1])\n",
        "\t  \n",
        "    #escogemos aleatoriamente una imagen de su otra clase distinta para formar pareja negativa\n",
        "    negIdx = np.where(indice != label)[0]\n",
        "    idxC = np.random.choice(negIdx)\n",
        "    negImage = images[idxC]\n",
        "\t\t#añadimos la pareja y su clase\n",
        "    parejas.append([imagenActual, negImage])\n",
        "    clasesParejas.append([0])\n",
        "\n",
        "    #escogemos aleatoriamente otra imagen de su otra clase distinta para formar pareja negativa\n",
        "    negIdx = np.where(indice != label)[0]\n",
        "    salir = True\n",
        "    while salir:\n",
        "      idxD = np.random.choice(negIdx)\n",
        "      if not idxC == idxD:\n",
        "        salir = False\n",
        "    negImage = images[idxD]\n",
        "\t\t#añadimos la pareja y su clase\n",
        "    parejas.append([imagenActual, negImage])\n",
        "    clasesParejas.append([0])\n",
        "\t\n",
        "  return parejas, clasesParejas\n",
        "\n",
        "\"\"\"\n",
        "funcion para hacer parejas de imagenes, hace tantas positivas como se pueda sin \n",
        "repetir parejas y tantas negativas como positivas tengamos\n",
        "Entrada: un diccionario en el que las claves son las clases y contiene una lista\n",
        "        con las imagenes que pertenezcan a esa clase\n",
        "Salida: una lista de parejas de imagenes y una lista de etiquetas podiendo ser estas\n",
        "        un 1 en caso de que ambas imagenes de la pareja pertenezca a la misma clase \n",
        "        y un 0 en caso contrario\n",
        "\"\"\"\n",
        "def hacerParejas(dict):\n",
        "\n",
        "  parejas = []\n",
        "  clases = []\n",
        "\n",
        "  #para cada calse\n",
        "  for clave in dict:\n",
        "\n",
        "    imagenes = dict[clave] #obtenemos las imagenes de esa clase\n",
        "    \n",
        "    for i in range(len(imagenes)-1): #para cada una de estas imagenes\n",
        "\n",
        "      cantidadParejas = 0\n",
        "\n",
        "      #formamos las parejas con el resto de imagenes de esa clase sin que haya repeticion\n",
        "      for j in range(i+1,len(imagenes)):\n",
        "        parejas.append([imagenes[i],imagenes[j]])\n",
        "        clases.append(1)\n",
        "        cantidadParejas += 1\n",
        "      \n",
        "      #para cada una de las parejas formadas anteriormente formamos tambien una negativa aleatoria\n",
        "      for j in range(cantidadParejas):\n",
        "        while True:\n",
        "          aleatorio = np.random.randint(0,len(dict.keys()))\n",
        "          if not list(dict.keys())[aleatorio] == clave:\n",
        "            im = dict[list(dict.keys())[aleatorio]]\n",
        "            aleatorio = np.random.randint(0,len(im))\n",
        "            parejas.append([imagenes[i],im[aleatorio]])\n",
        "            clases.append(0)\n",
        "            break\n",
        "  \n",
        "  #hacemos una permutacion para desordenarlas\n",
        "  orden = np.random.permutation(len(parejas))\n",
        "  parejasFinal = []\n",
        "  clasesFinal = []\n",
        "  for i in orden:\n",
        "    parejasFinal.append(parejas[i])\n",
        "    clasesFinal.append(clases[i])\n",
        "  \n",
        "  return parejasFinal,clasesFinal\n",
        "\n",
        "\"\"\"\n",
        "funcion para calcular la distancia euclidea entre dos vectores de caracteristicas\n",
        "(funcion obtenida en la web:\n",
        "https://www.pyimagesearch.com/2020/11/30/siamese-networks-with-keras-tensorflow-and-deep-learning/)\n",
        "Entrada: los vectores de caracteristicas \n",
        "Salida: la distancia entre ellos \n",
        "\"\"\"\n",
        "def euclidean_distance(vectors):\n",
        "\t\n",
        "\t(featsA, featsB) = vectors #obtenemos los dos vectores\n",
        "\tsumSquared = K.sum(K.square(featsA - featsB), axis=1, keepdims=True) #suma de distancias cuadradas\n",
        "\n",
        "\treturn K.sqrt(K.maximum(sumSquared, K.epsilon()))\n",
        " \n",
        "\"\"\"\n",
        "funcion para obtener la matriz de confusion de los resultados obtenidos\n",
        "Entrada: los resultados obtenidos y los resultadso correctos\n",
        "Salida: -\n",
        "\"\"\"\n",
        "def generarMatrizConfusion(bienIguales, malIguales, bienDistintas, malDistintas):\n",
        "\n",
        "  matrizConfusion = [[bienDistintas,\n",
        "                     malDistintas],\n",
        "                     [malIguales,\n",
        "                     bienIguales]]\n",
        "  \n",
        "  datos = pd.DataFrame(matrizConfusion)\n",
        "  sns.heatmap(datos, center=0, cmap='Blues_r', annot=True, fmt='.3f')\n",
        "\n",
        "\"\"\"\n",
        "funcion para completar, compilar y entrenar un modelo\n",
        "Entrada: el tamaño de las imagenes y los conjuntos de entrenamiento y validacion\n",
        "Salida: el modelo y la historia del entrenamiento\n",
        "\"\"\"\n",
        "def completarCompilarEntrenarModelo(model,tamImagenes,par_x_train_final,par_y_train_final,par_x_val,par_y_val):\n",
        "\n",
        "  #completamos el modelo\n",
        "  imgA = Input(tamImagenes)\n",
        "  imgB = Input(tamImagenes)\n",
        "  featureExtractor = model\n",
        "  featsA = featureExtractor(imgA)\n",
        "  featsB = featureExtractor(imgB)\n",
        "\n",
        "  distance = Lambda(euclidean_distance)([featsA, featsB])\n",
        "  outputs = Dense(1, activation=\"sigmoid\")(distance)\n",
        "  model = Model(inputs=[imgA, imgB], outputs=outputs)\n",
        "\n",
        "  #compilamos y declaramos el optimizador\n",
        "  optimizador = SGD(lr = 0.01, decay = 1e-6, momentum = 0.9, nesterov = True)\n",
        "  model.compile(loss=keras.losses.binary_crossentropy, optimizer=optimizador, metrics=['acc'])\n",
        "\n",
        "  #compilamos el modelo\n",
        "  history = model.fit([par_x_train_final[:,0], par_x_train_final[:,1]], par_y_train_final[:],validation_data=([par_x_val[:,0], par_x_val[:,1]], par_y_val[:]),\n",
        "\tbatch_size=batch_size, epochs=epochs)\n",
        "  \n",
        "  return model, history\n",
        "\n",
        "\"\"\"\n",
        "funcion para obtener las predicciones de un modelo sobre unas parejas de imagenes dadas\n",
        "Entrada: el modelo entrenado y el conjunto de test con sus etiquetas\n",
        "Salida: -\n",
        "\"\"\"\n",
        "def predecir(model,par_x_test,par_y_test):\n",
        "  bien1 = 0\n",
        "  mal1 = 0\n",
        "  mal2=0\n",
        "  bien2=0\n",
        "  total = 0\n",
        "  # loop over all image pairs\n",
        "  for i in range(len(par_x_test)):  \n",
        "    imageA = par_x_test[i,0]\n",
        "    imageB = par_x_test[i,1]\n",
        "\n",
        "    origA = imageA.copy()\n",
        "    origB = imageB.copy()\n",
        "    # add channel a dimension to both the images\n",
        "    imageA = np.expand_dims(imageA, axis=-1)\n",
        "    imageB = np.expand_dims(imageB, axis=-1)\n",
        "    # add a batch dimension to both images\n",
        "    imageA = np.expand_dims(imageA, axis=0)\n",
        "    imageB = np.expand_dims(imageB, axis=0)\n",
        "    # scale the pixel values to the range of [0, 1]\n",
        "    #imageA = imageA / 255.0\n",
        "    #imageB = imageB / 255.0\n",
        "    #print(imageB.shape)\n",
        "    # use our siamese model to make predictions on the image pair,\n",
        "    # indicating whether or not the images belong to the same class\n",
        "    preds = model.predict([imageA, imageB])\n",
        "    proba = preds[0][0]\n",
        "    if (proba > 0.4 ):\n",
        "      if (par_y_test[i]==1):\n",
        "        bien1 +=1\n",
        "      else:\n",
        "        mal1 +=1\n",
        "    else:\n",
        "      if (par_y_test[i]==0):\n",
        "        bien2 +=1\n",
        "      else:\n",
        "        mal2 +=1\n",
        "  generarMatrizConfusion(bien1,mal1,bien2,mal2)\n",
        "  total = bien1 + bien2 + mal1 + mal2\n",
        "  porc = (bien1+bien2)*100 / total\n",
        "  print(\"Ha acertado \", (bien1+bien2), \" y ha fallado \", (mal1+mal2), \" de un total de \", total, \" siendo un \", porc )"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oh0xvI8ENcq"
      },
      "source": [
        "# Modelos utilizados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "We18539REP93"
      },
      "source": [
        "\"\"\"\n",
        "primer modelo implementado cogido de la siguiente web:\n",
        "https://www.pyimagesearch.com/2020/11/30/siamese-networks-with-keras-tensorflow-and-deep-learning/\n",
        "\"\"\"\n",
        "def submodelo_prueba(inputShape):\n",
        "  \n",
        "\tinputs = Input(inputShape) #especificamos el tamaño de las imagenes de entrada\n",
        "\n",
        "\t#definimos el conjunto de capas: CONV => RELU => POOL => DROPOUT\n",
        "\tx = Conv2D(64, (2, 2), padding=\"same\", activation=\"relu\")(inputs)\n",
        "\tx = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\tx = Dropout(0.3)(x)\n",
        "\t#definimos el segundo conjunto de capas: CONV => RELU => POOL => DROPOUT \n",
        "\tx = Conv2D(64, (2, 2), padding=\"same\", activation=\"relu\")(x)\n",
        "\tx = MaxPooling2D(pool_size=2)(x)\n",
        "\tx = Dropout(0.3)(x)\n",
        "  \n",
        "  #preparamos el output final\n",
        "\tpooledOutput = GlobalAveragePooling2D()(x)\n",
        "\toutputs = Dense(274)(pooledOutput)\n",
        "\tmodel = Model(inputs, outputs) #contruimos el modelo\n",
        "\n",
        "\treturn model\n",
        "\n",
        "\"\"\"\n",
        "segundo modelo escogido: modelo basado en la red resnet50 preentrenada con imagenet\n",
        "al que se le ha añadido una capa dense al final con 274 (numero de clases que tenemos)\n",
        "\"\"\"\n",
        "def submodelo(inputShape):\n",
        "\n",
        "  resnet50 = ResNet50(weights='imagenet', include_top=False, pooling=\"avg\", input_shape=inputShape) #obtenemos resnet50\n",
        "\n",
        "  #indicamos que no vuelva a entrenar las capas\n",
        "  for layer in resnet50.layers:\n",
        "    if (not isinstance(layer, keras.layers.BatchNormalization)): #keras tiene un bug con batchNormalization\n",
        "      layer.trainable = False\n",
        "\n",
        "  #preparamos el output final\n",
        "  x = resnet50.output\n",
        "  x = Dense(274)(x)\n",
        "\n",
        "  model = Model(inputs = resnet50.input, outputs = x) #construimos el modelo\n",
        "\n",
        "  return model\n",
        "\n",
        "\"\"\"\n",
        "tercer modelo escogido: modelo basado en la red resnet50 preentrenada con imagenet\n",
        "al que se le ha añadido una capa dense al final con 274 (numero de clases que tenemos)\n",
        "y haciendo fine-tunning sobre una serie de capas\n",
        "\"\"\"\n",
        "def submodelo_fine_tunning(inputShape,numero_capas):\n",
        "\n",
        "  resnet50 = ResNet50(weights='imagenet', include_top=False, pooling=\"avg\", input_shape=inputShape) #obtenemos resnet50\n",
        "\n",
        "  #hacemos fine-tunning\n",
        "  for layer in resnet50.layers[:numero_capas]: \n",
        "    if (not isinstance(layer, keras.layers.BatchNormalization)):  #keras tiene un bug con batchNormalization\n",
        "      layer.trainable = False\n",
        "\n",
        "  #preparamos el output final\n",
        "  x = resnet50.output\n",
        "  x = Dense(274)(x)\n",
        "\n",
        "  model = Model(inputs = resnet50.input, outputs = x) #construimos el modelo\n",
        "\n",
        "  return model"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ca7nuxtlWB7n"
      },
      "source": [
        "#Constantes utilizadas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WIsY-PfWGei"
      },
      "source": [
        "batch_size = 32\n",
        "num_classes = 25\n",
        "epochs = 30"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6brXSvYNBZE"
      },
      "source": [
        "# Código principal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjpCK9g9WSKd"
      },
      "source": [
        "carga de imagenes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PKZrP-_TJoj"
      },
      "source": [
        "#cargamos las imagenes\n",
        "dicTrain, dicTest = cargarImagenesAirBnb()\n",
        "dicTrain = eliminarEjemplosNoValidos(dicTrain)\n",
        "dicTest = eliminarEjemplosNoValidos(dicTest)\n",
        "print('imagenes cargadas correctamente')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUJwVc9PWUZq"
      },
      "source": [
        "primera version: submodelo_prueba y parejas formadas con make_pairs_v1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbIxMBWeI34_"
      },
      "source": [
        "#generamos las parejas de imagenes\n",
        "x_train, y_train, x_test, y_test = cargarDatos(dicTrain,dicTest)\n",
        "par_x_train , par_y_train = make_pairs_v1(x_train,y_train)\n",
        "par_x_test, par_y_test = make_pairs_v1(x_test,y_test)\n",
        "print('parejas creadas correctamente')\n",
        "\n",
        "#obtenemos el modelo\n",
        "modelo = submodelo_prueba((256,256,3))\n",
        "modelo.summary()\n",
        "print('modelo obtenido con exito')\n",
        "\n",
        "#formamos el conjunto de validacion y entrenamos el modelo\n",
        "par_x_train_final, par_y_train_final, par_x_val, par_y_val = formarValidation(par_x_train,par_y_train,0.8 )\n",
        "par_x_train_final = np.asarray(par_x_train_final)\n",
        "par_y_train_final = np.asarray(par_y_train_final)\n",
        "par_x_val = np.asarray(par_x_val)\n",
        "par_y_val = np.asarray(par_y_val)\n",
        "print('conjunto validation obtenido correctamente')\n",
        "\n",
        "model, hist = completarCompilarEntrenarModelo(modelo,(256,256,3),par_x_train_final,par_y_train_final,par_x_val,par_y_val)\n",
        "print('entrenamiento completado')\n",
        "mostrarEvolucion(hist)\n",
        "\n",
        "#realizamos las predicciones\n",
        "par_x_test = np.asarray(par_x_test)\n",
        "par_y_test = np.asarray(par_y_test)\n",
        "predecir(model,par_x_test,par_y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxJVwI__Wh1A"
      },
      "source": [
        "segunda version: submodelo y parejas formadas con make_pairs_v1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0MSXbMyXH6L"
      },
      "source": [
        "#generamos las parejas de imagenes\n",
        "x_train, y_train, x_test, y_test = cargarDatos(dicTrain,dicTest)\n",
        "par_x_train , par_y_train = make_pairs_v1(x_train,y_train)\n",
        "par_x_test, par_y_test = make_pairs_v1(x_test,y_test)\n",
        "print('parejas creadas correctamente')\n",
        "\n",
        "#obtenemos el modelo\n",
        "modelo = submodelo((256,256,3))\n",
        "modelo.summary()\n",
        "print('modelo obtenido con exito')\n",
        "\n",
        "#formamos el conjunto de validacion y entrenamos el modelo\n",
        "par_x_train_final, par_y_train_final, par_x_val, par_y_val = formarValidation(par_x_train,par_y_train,0.8 )\n",
        "par_x_train_final = np.asarray(par_x_train_final)\n",
        "par_y_train_final = np.asarray(par_y_train_final)\n",
        "par_x_val = np.asarray(par_x_val)\n",
        "par_y_val = np.asarray(par_y_val)\n",
        "print('conjunto validation obtenido correctamente')\n",
        "\n",
        "model, hist = completarCompilarEntrenarModelo(modelo,(256,256,3),par_x_train_final,par_y_train_final,par_x_val,par_y_val)\n",
        "print('entrenamiento completado')\n",
        "mostrarEvolucion(hist)\n",
        "\n",
        "#realizamos las predicciones\n",
        "par_x_test = np.asarray(par_x_test)\n",
        "par_y_test = np.asarray(par_y_test)\n",
        "predecir(model,par_x_test,par_y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XpRX_YwJWk70"
      },
      "source": [
        "tercera version: submodelo y parejas formadas con make_pairs_v2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-e3ZRsNXIlq"
      },
      "source": [
        "#generamos las parejas de imagenes\n",
        "x_train, y_train, x_test, y_test = cargarDatos(dicTrain,dicTest)\n",
        "par_x_train , par_y_train = make_pairs_v2(x_train,y_train)\n",
        "par_x_test, par_y_test = make_pairs_v2(x_test,y_test)\n",
        "print('parejas creadas correctamente')\n",
        "\n",
        "#obtenemos el modelo\n",
        "modelo = submodelo((256,256,3))\n",
        "modelo.summary()\n",
        "print('modelo obtenido con exito')\n",
        "\n",
        "#formamos el conjunto de validacion y entrenamos el modelo\n",
        "par_x_train_final, par_y_train_final, par_x_val, par_y_val = formarValidation(par_x_train,par_y_train,0.8 )\n",
        "par_x_train_final = np.asarray(par_x_train_final)\n",
        "par_y_train_final = np.asarray(par_y_train_final)\n",
        "par_x_val = np.asarray(par_x_val)\n",
        "par_y_val = np.asarray(par_y_val)\n",
        "print('conjunto validation obtenido correctamente')\n",
        "\n",
        "model, hist = completarCompilarEntrenarModelo(modelo,(256,256,3),par_x_train_final,par_y_train_final,par_x_val,par_y_val)\n",
        "print('entrenamiento completado')\n",
        "mostrarEvolucion(hist)\n",
        "\n",
        "#realizamos las predicciones\n",
        "par_x_test = np.asarray(par_x_test)\n",
        "par_y_test = np.asarray(par_y_test)\n",
        "predecir(model,par_x_test,par_y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fbmZhk9Wl2r"
      },
      "source": [
        "cuarta version: submodelo y parejas formadas con make_pairs_v3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCVvjYALXJER"
      },
      "source": [
        "#generamos las parejas de imagenes\n",
        "x_train, y_train, x_test, y_test = cargarDatos(dicTrain,dicTest)\n",
        "par_x_train , par_y_train = make_pairs_v3(x_train,y_train)\n",
        "par_x_test, par_y_test = make_pairs_v3(x_test,y_test)\n",
        "print('parejas creadas correctamente')\n",
        "\n",
        "#obtenemos el modelo\n",
        "modelo = submodelo((256,256,3))\n",
        "modelo.summary()\n",
        "print('modelo obtenido con exito')\n",
        "\n",
        "#formamos el conjunto de validacion y entrenamos el modelo\n",
        "par_x_train_final, par_y_train_final, par_x_val, par_y_val = formarValidation(par_x_train,par_y_train,0.8 )\n",
        "par_x_train_final = np.asarray(par_x_train_final)\n",
        "par_y_train_final = np.asarray(par_y_train_final)\n",
        "par_x_val = np.asarray(par_x_val)\n",
        "par_y_val = np.asarray(par_y_val)\n",
        "print('conjunto validation obtenido correctamente')\n",
        "\n",
        "model, hist = completarCompilarEntrenarModelo(modelo,(256,256,3),par_x_train_final,par_y_train_final,par_x_val,par_y_val)\n",
        "print('entrenamiento completado')\n",
        "mostrarEvolucion(hist)\n",
        "\n",
        "#realizamos las predicciones\n",
        "par_x_test = np.asarray(par_x_test)\n",
        "par_y_test = np.asarray(par_y_test)\n",
        "predecir(model,par_x_test,par_y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHTYA8_KWm2V"
      },
      "source": [
        "quinta version: submodelo y parejas formadas con hacerParejas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76t7xg0_XJhw"
      },
      "source": [
        "#generamos las parejas de imagenes\n",
        "par_x_train, par_y_train = hacerParejas(dicTrain)\n",
        "par_x_test, par_y_test = hacerParejas(dicTest)\n",
        "print('parejas creadas correctamente')\n",
        "\n",
        "#obtenemos el modelo\n",
        "modelo = submodelo((256,256,3))\n",
        "modelo.summary()\n",
        "print('modelo obtenido con exito')\n",
        "\n",
        "#formamos el conjunto de validacion y entrenamos el modelo\n",
        "par_x_train_final, par_y_train_final, par_x_val, par_y_val = formarValidation(par_x_train,par_y_train,0.8 )\n",
        "par_x_train_final = np.asarray(par_x_train_final)\n",
        "par_y_train_final = np.asarray(par_y_train_final)\n",
        "par_x_val = np.asarray(par_x_val)\n",
        "par_y_val = np.asarray(par_y_val)\n",
        "print('conjunto validation obtenido correctamente')\n",
        "\n",
        "model, hist = completarCompilarEntrenarModelo(modelo,(256,256,3),par_x_train_final,par_y_train_final,par_x_val,par_y_val)\n",
        "print('entrenamiento completado')\n",
        "mostrarEvolucion(hist)\n",
        "\n",
        "#realizamos las predicciones\n",
        "par_x_test = np.asarray(par_x_test)\n",
        "par_y_test = np.asarray(par_y_test)\n",
        "predecir(model,par_x_test,par_y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLqbC2IVWpXv"
      },
      "source": [
        "sexta version: submodelo_fine_tunning de todas las capas y parejas formadas con hacerParejas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-36EpUpXKAJ"
      },
      "source": [
        "#generamos las parejas de imagenes\n",
        "par_x_train, par_y_train = hacerParejas(dicTrain)\n",
        "par_x_test, par_y_test = hacerParejas(dicTest)\n",
        "print('parejas creadas correctamente')\n",
        "\n",
        "#obtenemos el modelo\n",
        "modelo = submodelo_fine_tunning((256,256,3),0)\n",
        "modelo.summary()\n",
        "print('modelo obtenido con exito')\n",
        "\n",
        "#formamos el conjunto de validacion y entrenamos el modelo\n",
        "par_x_train_final, par_y_train_final, par_x_val, par_y_val = formarValidation(par_x_train,par_y_train,0.8 )\n",
        "par_x_train_final = np.asarray(par_x_train_final)\n",
        "par_y_train_final = np.asarray(par_y_train_final)\n",
        "par_x_val = np.asarray(par_x_val)\n",
        "par_y_val = np.asarray(par_y_val)\n",
        "print('conjunto validation obtenido correctamente')\n",
        "\n",
        "model, hist = completarCompilarEntrenarModelo(modelo,(256,256,3),par_x_train_final,par_y_train_final,par_x_val,par_y_val)\n",
        "print('entrenamiento completado')\n",
        "mostrarEvolucion(hist)\n",
        "\n",
        "#realizamos las predicciones\n",
        "par_x_test = np.asarray(par_x_test)\n",
        "par_y_test = np.asarray(par_y_test)\n",
        "predecir(model,par_x_test,par_y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDbUF2HfWv13"
      },
      "source": [
        "septima version: submodelo_fine_tunning con el 20% de las capas reentrenadas y parejas formadas con hacerParejas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTTY0R_XXKe8"
      },
      "source": [
        "#generamos las parejas de imagenes\n",
        "par_x_train, par_y_train = hacerParejas(dicTrain)\n",
        "par_x_test, par_y_test = hacerParejas(dicTest)\n",
        "print('parejas creadas correctamente')\n",
        "\n",
        "#obtenemos el modelo\n",
        "modelo = submodelo_fine_tunning((256,256,3),10)\n",
        "modelo.summary()\n",
        "print('modelo obtenido con exito')\n",
        "\n",
        "#formamos el conjunto de validacion y entrenamos el modelo\n",
        "par_x_train_final, par_y_train_final, par_x_val, par_y_val = formarValidation(par_x_train,par_y_train,0.8 )\n",
        "par_x_train_final = np.asarray(par_x_train_final)\n",
        "par_y_train_final = np.asarray(par_y_train_final)\n",
        "par_x_val = np.asarray(par_x_val)\n",
        "par_y_val = np.asarray(par_y_val)\n",
        "print('conjunto validation obtenido correctamente')\n",
        "\n",
        "model, hist = completarCompilarEntrenarModelo(modelo,(256,256,3),par_x_train_final,par_y_train_final,par_x_val,par_y_val)\n",
        "print('entrenamiento completado')\n",
        "mostrarEvolucion(hist)\n",
        "\n",
        "#realizamos las predicciones\n",
        "par_x_test = np.asarray(par_x_test)\n",
        "par_y_test = np.asarray(par_y_test)\n",
        "predecir(model,par_x_test,par_y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3Yg1GO2v00w"
      },
      "source": [
        "#Bibliografia:  \n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4nkqVi6YeXv"
      },
      "source": [
        "* https://stackoverflow.com/questions/43977463/valueerror-could-not-broadcast-input-array-from-shape-224-224-3-into-shape-2\n",
        "\n",
        "* https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/load_img\n",
        "\n",
        "*  https://en.wikipedia.org/wiki/Cropping_(image)\n",
        "* https://jkjung-avt.github.io/keras-image-cropping/\n",
        "* https://www.pyimagesearch.com/2020/11/30/siamese-networks-with-keras-tensorflow-and-deep-learning/\n",
        "* https://www.pyimagesearch.com/2021/01/18/contrastive-loss-for-siamese-networks-with-keras-and-tensorflow/\n",
        "* http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
        "* https://stats.stackexchange.com/questions/388859/is-it-possible-to-give-variable-sized-images-as-input-to-a-convolutional-neural\n",
        "* https://medium.com/@prabhnoor0212/siamese-network-keras-31a3a8f37d04\n",
        "\n",
        "* https://keras.io/api/optimizers/adam/"
      ]
    }
  ]
}